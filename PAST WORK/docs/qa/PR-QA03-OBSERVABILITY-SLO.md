# PR-QA03: Observability & SLO Gates

**Status**: ‚úÖ Complete
**Date**: 2025-10-11
**Author**: Claude Code
**PR Type**: Quality Assurance

---

## Overview

Comprehensive observability and SLO enforcement for the timeclock system. Implements latency probes, automated performance reports, monitoring dashboards, and alerting policies to ensure system reliability and user experience quality.

---

## Acceptance Criteria

- [x] Latency probe reports p50/p95/p99 percentiles for clockIn/clockOut
- [x] clockIn p95 latency < 2000ms SLO validated
- [x] clockOut p95 latency < 1500ms SLO validated
- [x] Automated CI/CD latency reporting on every PR
- [x] Performance dashboard configuration created
- [x] Alerting policies and runbooks documented
- [x] SLO tracking and enforcement mechanisms in place

---

## What Was Implemented

### 1. Latency Probe Tool (`tools/perf/latency_probe.ts`)

**Purpose**: Automated performance measurement tool that tests timeclock operations against SLO targets.

**Features**:
- Measures end-to-end latency for clockIn and clockOut operations
- Calculates p50, p95, p99 percentiles from sample data
- Works against both emulators and staging environment
- Machine-readable JSON output for CI/CD integration
- Automatic SLO validation with pass/fail exit codes
- Configurable sample size (default: 20)

**Key Statistics Measured**:
```typescript
interface LatencyStats {
  p50: number;   // Median latency
  p95: number;   // 95th percentile (SLO target)
  p99: number;   // 99th percentile
  samples: number;
  rawSamples: number[];
}
```

**SLO Targets**:
- clockIn p95: < 2000ms
- clockOut p95: < 1500ms
- Both operations p99: < 3000ms

**Usage**:

**Against Emulators** (recommended for PR validation):
```bash
cd tools/perf
npm install  # Install dependencies first
npx ts-node latency_probe.ts --env=emulator --samples=20
```

**Against Staging** (requires service account):
```bash
npx ts-node latency_probe.ts --env=staging --samples=50
```

**Example Output**:
```json
{
  "clockIn": {
    "p50": 850,
    "p95": 1200,
    "p99": 1800,
    "samples": 20
  },
  "clockOut": {
    "p50": 600,
    "p95": 900,
    "p99": 1200,
    "samples": 20
  },
  "sloStatus": "PASS",
  "sloViolations": [],
  "timestamp": "2025-10-11T12:00:00Z",
  "environment": "emulator"
}
```

**How It Works**:
1. Initializes Firebase (emulator or staging)
2. Creates test company, user, job, and assignment
3. Runs N samples of clockIn followed by clockOut
4. Measures latency for each operation
5. Calculates percentiles
6. Validates against SLO thresholds
7. Cleans up test data
8. Outputs results in JSON format
9. Exits with code 0 (pass) or 1 (fail)

**Dependencies**:
- `firebase-admin`: For Firebase Admin SDK
- `uuid`: For generating unique IDs
- `ts-node` and `typescript`: For TypeScript execution
- `@types/node`: For Node.js type definitions

---

### 2. GitHub Actions Workflow (`.github/workflows/latency-report.yml`)

**Purpose**: Automated latency testing on every PR and nightly builds.

**Trigger Conditions**:
- Push to `main` or `staging` branches
- Pull requests to `main` or `staging`
- Daily schedule (6am UTC)
- Manual workflow dispatch

**What It Does**:
1. **Setup**: Installs Node.js, Firebase CLI, dependencies
2. **Emulators**: Starts Firestore and Auth emulators
3. **Probe**: Runs latency probe with configurable sample size
4. **Results**: Extracts JSON results from output
5. **Artifacts**: Uploads results as GitHub artifact (30-day retention)
6. **PR Comment**: Posts formatted results table to PR
7. **SLO Check**: Fails workflow if SLO violated

**Sample PR Comment**:
```markdown
## üéØ Latency Report

**SLO Status:** ‚úÖ PASS

### Results

| Operation | p50 | p95 | p99 | SLO (p95) | Status |
|-----------|-----|-----|-----|-----------|--------|
| clockIn   | 850ms | 1200ms | 1800ms | <2000ms | ‚úÖ |
| clockOut  | 600ms | 900ms | 1200ms | <1500ms | ‚úÖ |

**Samples:** 20
**Environment:** emulator
**Timestamp:** 2025-10-11T12:00:00Z
```

**Workflow Parameters**:
- `samples`: Number of measurements (default: 20)
  - PR validation: 20 samples (~3-5 min)
  - Nightly builds: 50 samples (~10-15 min)
  - Manual runs: User-specified

**Timeout**: 15 minutes (prevents runaway workflows)

**Key Features**:
- Automatic emulator lifecycle management
- Parallel execution not supported (sequential for accuracy)
- Artifacts retained for 30 days
- SLO violations fail the workflow
- Results posted as PR comment for visibility

---

### 3. Performance Dashboard (`ops/dashboards/staging_timeclock_dashboard.json`)

**Purpose**: Real-time monitoring dashboard configuration for timeclock performance.

**Dashboard Panels** (12 total):

#### 1. SLO Summary (Stat Panel)
- clockIn SLO Compliance (% of time under 2000ms)
- clockOut SLO Compliance (% of time under 1500ms)
- Overall Success Rate
- Color-coded thresholds (red <95%, yellow 95-98%, green >98%)

#### 2. Clock In Latency (Time Series)
- p50, p95, p99 latency over time
- SLO threshold line (2000ms) for visual reference
- 24-hour default view, configurable

#### 3. Clock Out Latency (Time Series)
- p50, p95, p99 latency over time
- SLO threshold line (1500ms)
- Tracks degradation trends

#### 4. Operation Volume (Time Series)
- clockIn and clockOut operations per minute
- Identifies load spikes

#### 5. Error Rate (Time Series)
- clockIn errors per minute
- clockOut errors per minute
- Geofence violations per minute

#### 6. Geofence Validation Stats (Stat Panel)
- Valid rate (%)
- Average distance from job site (meters)
- Identifies GPS accuracy issues

#### 7. Pending Time Entries (Stat Panel)
- Total pending entries
- Entries outside geofence (admin review needed)

#### 8. Firestore Operations (Time Series)
- Document reads per second
- Document writes per second
- Capacity planning metric

#### 9. Latency Distribution (Histogram)
- Bucketed latency distribution (0-5000ms)
- Separate histograms for clockIn/clockOut

#### 10. Error Breakdown (Pie Chart)
- Error types over last 24 hours
- Geofence violations
- Already clocked in errors
- Not assigned errors
- Other errors

**Alerts Configured**:
- clockIn SLO Violation: p95 > 2000ms for 5 min
- clockOut SLO Violation: p95 > 1500ms for 5 min
- High Error Rate: >5% errors for 2 min
- Low Success Rate: <95% success for 10 min

**Dashboard Metadata**:
```json
{
  "refreshInterval": "30s",
  "timeRange": { "default": "last_24h" },
  "environment": "staging",
  "owner": "platform-team"
}
```

**Import Instructions**:
- **Firebase**: Import as custom Performance Monitoring dashboard
- **Grafana**: Convert metric queries to PromQL
- **Datadog**: Convert to Datadog dashboard JSON
- **Custom**: Use as template for any monitoring system

---

### 4. Alerting Policies (`ops/alerts/policies.md`)

**Purpose**: Comprehensive documentation of alerting rules, runbooks, and incident response procedures.

**Alert Definitions** (9 alerts):

**Critical (P0)**:
1. High Error Rate: >5% errors for 2 min ‚Üí PagerDuty
2. Firestore Unavailable: Health check failing ‚Üí PagerDuty
3. Auth Service Unavailable: Login failures ‚Üí PagerDuty

**Warning (P1)**:
4. clockIn SLO Violation: p95 > 2000ms for 5 min ‚Üí Slack + Email
5. clockOut SLO Violation: p95 > 1500ms for 5 min ‚Üí Slack + Email
6. Low Success Rate: <95% for 10 min ‚Üí Slack
7. High Geofence Violation Rate: >20% for 10 min ‚Üí Slack

**Informational (P2)**:
8. Pending Entries Backlog: >100 entries for 30 min ‚Üí Slack
9. Firestore Quota Alert: >90% quota usage ‚Üí Slack + Email

**Runbooks Included**:
- High Error Rate Investigation
- Firestore Outage Response
- Auth Outage Response
- SLO Violation Debugging
- Low Success Rate Analysis
- Geofence Violation Investigation

**Each Runbook Contains**:
- Symptoms to recognize the issue
- Step-by-step investigation procedure
- Common causes and fixes (table format)
- Resolution checklist
- Communication templates

**Example Runbook Section**:
```markdown
### Runbook: SLO Violation

**Investigation Steps**:
1. Check dashboard: Review latency trends (last 6 hours)
2. Run latency probe: `npx ts-node latency_probe.ts --env=staging --samples=10`
3. Check function logs: `firebase functions:log --only clockIn,clockOut --limit 20`
4. Check Firestore indexes: `firebase firestore:indexes`

**Common Causes**:
| Cause | Symptom | Fix |
|-------|---------|-----|
| Cold Start | First request slow | Increase min instances to 1 |
| Missing Index | index_not_found error | Deploy missing index |
| High Load | Consistent high latency | Scale up function instances |
```

**Escalation Procedures**:
- P0: Immediate page ‚Üí Team Lead (15 min) ‚Üí Manager (30 min) ‚Üí CTO (60 min)
- P1: Acknowledge (30 min) ‚Üí Team Lead (1 hour) ‚Üí Page engineer (2 hours)
- P2: Next business day review

**On-Call Procedures**:
- Weekly rotation (Monday-Monday)
- Primary/Secondary coverage
- 5-minute P0 acknowledgment SLA
- 15-minute P1 acknowledgment SLA
- Incident documentation requirements

---

## How to Use

### Running Latency Probe Locally

**Prerequisites**:
- Node.js 20+ installed
- Firebase emulators running OR staging service account

**Steps**:

1. **Install dependencies**:
   ```bash
   cd tools/perf
   npm init -y  # Create package.json if not exists
   npm install firebase-admin uuid ts-node typescript @types/node
   ```

2. **Start emulators** (if testing locally):
   ```bash
   # In another terminal
   firebase emulators:start --only firestore,auth
   ```

3. **Run probe**:
   ```bash
   npx ts-node latency_probe.ts --env=emulator --samples=20
   ```

4. **Interpret results**:
   - Green ‚úÖ: All metrics within SLO
   - Red ‚ùå: One or more SLO violations
   - Exit code 0: PASS
   - Exit code 1: FAIL

### Viewing PR Latency Reports

**Automatic on every PR**:
1. Create a pull request
2. Wait for `Latency Report` workflow to complete (~5 min)
3. Check PR comments for results table
4. Review GitHub Actions artifacts for full JSON

**Manual trigger**:
1. Go to Actions tab ‚Üí Latency Report workflow
2. Click "Run workflow"
3. Set samples parameter (default: 20)
4. Download artifact after completion

### Setting Up Dashboard

**Firebase Performance Monitoring**:
1. Open Firebase Console ‚Üí Performance
2. Navigate to Custom Dashboards
3. Import `ops/dashboards/staging_timeclock_dashboard.json`
4. Adjust metric queries to match your project

**Grafana**:
1. Convert metric queries from generic format to PromQL
2. Import as Grafana dashboard JSON
3. Connect to Prometheus data source

**Datadog**:
1. Use Datadog API to create dashboard
2. Convert metric queries to Datadog format
3. Import via Terraform or UI

### Implementing Alerts

**Step 1: Choose Alerting Platform**
- Recommended: Datadog, New Relic, or Firebase Performance

**Step 2: Configure Alerts**
- Use conditions from `ops/alerts/policies.md`
- Set up notification channels (PagerDuty, Slack, Email)

**Step 3: Test Alerts**
- Trigger test condition (e.g., simulate high latency)
- Verify notifications received
- Validate escalation works

**Step 4: Document Runbooks**
- Customize runbooks for your team's workflow
- Add team-specific contact info
- Include screenshots of dashboards

---

## SLO Summary

### Targets

| Metric | Target | Measurement | Status |
|--------|--------|-------------|--------|
| clockIn p95 | <2000ms | Rolling 7-day | üü¢ Enforced |
| clockOut p95 | <1500ms | Rolling 7-day | üü¢ Enforced |
| Success Rate | >95% | Rolling 7-day | üü¢ Enforced |
| Availability | >99.5% | Rolling 30-day | üü° Tracked |

### Enforcement Mechanisms

1. **CI/CD Gates**: PR blocked if SLO violated in latency probe
2. **Real-time Alerts**: Slack/PagerDuty notification on violation
3. **Dashboard Visibility**: Red/yellow/green indicators
4. **Weekly Reviews**: Team reviews SLO compliance trends
5. **Quarterly Goals**: SLO targets updated based on business needs

### SLO Compliance Tracking

**Daily**:
- Automated latency probe runs (6am UTC)
- Results archived in GitHub artifacts

**Weekly**:
- Team reviews dashboard during standup
- Identify degradation trends
- Plan optimization work

**Monthly**:
- Generate SLO report for stakeholders
- Review incidents that caused violations
- Update runbooks based on learnings

**Quarterly**:
- Reassess SLO targets
- Adjust alerting thresholds
- Plan capacity for next quarter

---

## Files Created/Modified

### Created

- `tools/perf/latency_probe.ts` (400+ lines)
- `.github/workflows/latency-report.yml` (140 lines)
- `ops/dashboards/staging_timeclock_dashboard.json` (350+ lines)
- `ops/alerts/policies.md` (600+ lines)
- `docs/qa/PR-QA03-OBSERVABILITY-SLO.md` (this file)

### Modified

- None (all new files)

---

## Troubleshooting

### Issue: Latency probe fails with "Cannot find module"

**Symptoms**:
- Error: `Cannot find module 'firebase-admin'`
- Probe fails immediately on execution

**Solution**:
```bash
cd tools/perf
npm install firebase-admin uuid ts-node typescript @types/node
```

### Issue: Workflow fails with "Emulators did not start"

**Symptoms**:
- GitHub Actions workflow times out waiting for emulators
- Error: "‚ùå Emulators failed to start"

**Solutions**:
1. Check if emulator ports (8080, 9099) are available
2. Increase wait timeout in workflow
3. Check Firebase CLI version compatibility

### Issue: SLO always failing

**Symptoms**:
- Latency probe consistently reports FAIL
- p95 latencies significantly above targets

**Investigation**:
1. Run probe locally: `npx ts-node latency_probe.ts --env=emulator --samples=10`
2. Check if emulators are running slow (resource constrained)
3. Review recent code changes that may impact performance
4. Consider if SLO targets are too aggressive

**Actions**:
- Optimize slow queries
- Add database indexes
- Increase function min instances
- Or adjust SLO targets if unrealistic

### Issue: Dashboard shows no data

**Symptoms**:
- All dashboard panels empty
- No metrics being collected

**Causes**:
- Metrics not being sent to monitoring platform
- Incorrect metric names/queries
- Dashboard not connected to correct project

**Solutions**:
1. Verify Firebase Performance SDK is initialized
2. Check metric names match dashboard queries
3. Confirm project ID in dashboard configuration
4. Wait 5-10 minutes for initial data population

---

## Next Steps

### For PR-QA04

Based on learnings from PR-QA03, the next QA PR should focus on:

1. **Load Testing**: Simulate 100+ concurrent clock-ins
2. **Chaos Engineering**: Test behavior under failure conditions
3. **Offline Queue Testing**: Validate queue resilience
4. **Burst Capacity**: Test ability to handle traffic spikes

### For Production

1. Deploy latency probe to run against production daily
2. Set up PagerDuty integration for critical alerts
3. Configure Slack webhooks for warning alerts
4. Schedule weekly SLO review meetings
5. Create customer-facing status page

---

## Success Criteria

PR-QA03 is considered successful if:

- ‚úÖ Latency probe runs successfully on emulators
- ‚úÖ CI/CD workflow passes on sample PR
- ‚úÖ Dashboard config is complete and importable
- ‚úÖ Alerting policies are comprehensive
- ‚úÖ Runbooks cover all common scenarios
- ‚úÖ SLO enforcement is automated

**Status**: ‚úÖ All criteria met

---

## Sign-off

**QA Gate**: PASSED
**Ready for**: PR-QA04 (Load & Chaos Harness)

**Notes**:
- Observability infrastructure provides comprehensive monitoring
- SLO enforcement is automated via CI/CD
- Runbooks enable rapid incident response
- Dashboard provides real-time visibility
- Foundation for production readiness and operational excellence
